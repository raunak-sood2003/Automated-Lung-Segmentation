{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from clsfr_data_loading import lungCT_clsfr_DATA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lungPartitionClsfr(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super(lungPartitionClsfr, self).__init__()\n",
    "        self.max_pool2d = nn.MaxPool2d(2)\n",
    "        self.down_conv1 = self.double_conv(in_c, 64)\n",
    "        self.down_conv2 = self.double_conv(64, 64)\n",
    "        self.down_conv3 = self.double_conv(64, 128)\n",
    "        self.down_conv4 = self.double_conv(128, 128)\n",
    "        self.linear1 = nn.Linear(28*28*128, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, out_c)\n",
    "        \n",
    "    def double_conv(self, in_c, out_c, kernel_size = 3, padding = 0):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size = kernel_size, padding = padding),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size = kernel_size, padding = padding),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace = True))\n",
    "        return conv\n",
    "    \n",
    "    def forward(self, x0):\n",
    "        x1 = self.down_conv1(x0)\n",
    "        p1 = self.max_pool2d(x1)\n",
    "        x2 = self.down_conv2(p1)\n",
    "        p2 = self.max_pool2d(x2)\n",
    "        x3 = self.down_conv3(p2)\n",
    "        p3 = self.max_pool2d(x3)\n",
    "        x4 = self.down_conv4(p3)\n",
    "        p4 = self.max_pool2d(x4)\n",
    "        p4 = p4.view(-1, 28*28*128)\n",
    "        x5 = self.linear1(p4)\n",
    "        x5 = F.relu(x5)\n",
    "        x6 = self.linear2(x5)\n",
    "        x6 = F.relu(x6)\n",
    "        x7 = self.linear3(x6)\n",
    "        x7 = torch.softmax(x7, 1)\n",
    "        \n",
    "        return x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from clsfr_data_loading import lungCT_clsfr_DATA\n",
    "import numpy as np\n",
    "from tqdm as tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "pth = '/home/rrsood003/DATA/classifier_pairs.npy'\n",
    "classifier_pairs = np.load(pth, allow_pickle = True)\n",
    "\n",
    "batch_size = 16\n",
    "train = lungCT_clsfr_DATA(classifier_pairs, 'train')\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "val = lungCT_clsfr_DATA(classifier_pairs, 'val')\n",
    "val_loader = DataLoader(val, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_save = True\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "model = lungPartitionClsfr(1, 3).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        X_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        output_train = model(X_batch)\n",
    "        loss_train = criterion(output_train, y_batch)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_train.item()\n",
    "        \n",
    "        for idx, y in enumerate(y_batch):\n",
    "            if torch.argmax(y) == torch.argmax(output_train[idx]):\n",
    "                train_correct += 1\n",
    "            train_total += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()        \n",
    "        for batch_val in tqdm(val_loader):\n",
    "            X_val, y_val = batch_val[0].to(device), batch_val[1].to(device)\n",
    "            output_val = model(X_val)\n",
    "            loss_val = criterion(output_val, y_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "            for idx, y in enumerate(y_val):\n",
    "                if torch.argmax(y) == torch.argmax(output_val[idx]):\n",
    "                    val_correct += 1\n",
    "                val_total += 1\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(\"Epoch [%s]/[%s]\\tTrain Loss: %s\\tVal Loss: %s\\tTrain Acc: %s\\tVal Acc: %s\" \n",
    "          % (epoch, epochs, train_loss, val_loss, train_acc, val_acc))\n",
    "\n",
    "if to_save:\n",
    "    date = time.strftime(\"%D\").replace('/', '-')\n",
    "    clsfr_file = 'lungCT_clsfr_epoch%s_batch%s_%s' % (epochs, batch_size, date)\n",
    "    save_folder = '/home/rrsood003/Classifier/saved_models/' + clsfr_file\n",
    "    os.mkdir(save_folder)\n",
    "    torch.save(model, save_folder + clsfr_file + '.pth')\n",
    "    np.save(save_folder + 'train_losses.npy', np.array(train_losses))\n",
    "    np.save(save_folder + 'val_losses.npy', np.array(val_losses))\n",
    "    np.save(save_folder + 'train_accuracies.npy', np.array(train_accuracies))\n",
    "    np.save(save_folder + 'val_accuracies.npy', np.array(val_accuracies))\n",
    "    \n",
    "    \n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
